<h1>
<a name="chapter1" class="anchor" href="#chapter1"><span class="octicon octicon-link"></span></a>Chapter 1 - Algorithms</h1>

<!--
TODO: Finding max element
TODO: Eratosphenus sieve
TODO: Finding gcd

Excercises:
TODO: Determining if a string is a palindrome
TODO: Finding all the perfect numbers less than given number (sum of all positive dividers is equal to number)
TODO: Program that solves a quadratic equation, input three coefficients, output the found roots
-->

<p>In this chapter we discuss what is an algorithm, time complexity, storage complexity and provide a few examples of algorithms.
</p>

<h2>What is an algorithm?</h2>

<p>
Let's first start with a discussion of what an algorithm is. Intuitively the definition is more or less clear, we are talking about some formal way to describe a computational procedure. According to the Merriam-Webster dictionary algorithm is "a set of steps that are followed in order to solve a mathematical problem or to complete a computer process".
</p>

<p>
Still this is probably not formal enough. How do we choose the next steps from the set of steps? Should we stop eventually? What is the result of an execution of an algorithm? There can be given many formal definitions of what constitutes an algorithm, however, at this point in the book, without introducing the abstract models of computation and what computation is, we will just give the following definition.
</p>

<div class="highlighted">
<div class="definition-term">Algorithm</div>
Set of computational steps which specifies a formal computational procedure and has the following properties:
<ol class="lower-alpha">
  <li>After each step is completed the next step is unambiguously defined or the algorithm stops its execution if there are no more steps left</li>
  <li>It is defined on a set of inputs and for each input it stops after a finite number of steps</li>
  <li>When it stops it produces a result which we call its output</li>
  <li>Its steps and their order of execution can be formally and unambiguously specified using some language or notation</li>
</ol>
</div>
<div class="artefact-label" href="#1.1">1.1 - Algorithm</div>

Algorithms can be expressed in a variety of ways. We can even specify the execution steps using the normal human language.
Let's provide a few simple examples. First trivial example will be multiplying two numbers.

<div class="highlighted no-artefact-label">
<div class="example-title">Algorithm of integer number multiplication.</div>
Steps:
<ol>
<li>Given two integer numbers multiply them and return the result</li>
</ol>
</div>

<p>
All the points from the definition of the algorithm are satisfied. There is only one step, after this step algorithm stops, the step is formally specified, all the integer numbers are valid inputs and a valid result will be produced for them. If we denote the algorithm for multiplication as <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>mult</mi></math> then, for example, <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
<mstyle>
  <mi>mult</mi>
    <mrow>
      <mo>(</mo>
      <mi>2</mi>
      <mo>,</mo>
      <mi>5</mi>
      <mo>)</mo>
    </mrow>
  <mo>=</mo>
  <mi>10</mi>
</mstyle>
</math> and we can formally specify the algorithm as follows <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
<mstyle>
  <mi>mult</mi>
    <mrow>
      <mo>(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>y</mi>
      <mo>)</mo>
    </mrow>
  <mo>=</mo>
  <mi>x</mi>
  <mo>*</mo>
  <mi>y</mi>
</mstyle>
</math>.
</p>

<p>
So far while talking about algorithms we encountered no JavaScript or any other programming language notation. This is quite intentional since we now clearly see that the notion of an algorithm is more of a mathematical one and it is quite abstract. Of course we can express any algorithm using JavaScript but this will be just one of the possible formal representations, in this case also executable by a JavaScript engine.
</p>

<p>
A careful reader might be a bit puzzled by our confidence at this point. How can we state that any algorithm can be expressed using JavaScript? Can this be in fact proven given the definition of an algorithm we gave earlier? Is JavaScript in fact powerful enough to express all the algorithms there can be? It turns out it is, but we will leave this statement without any proof until the very end of the book where we will discuss abstract models of computation and give even more formal and strict definition of an algorithm.
</p>

<p>
Let's look again at the definition 1.1 of algorithm and its part that states that we should be able to specify the computational procedure formally. Now it is more or less clear why we require this property from an algorithm. Then we can use a formal language such as JavaScript to specify the algorithm of our interest and execute this formal specification by using a machine such as a laptop or even smartphone. For the number multiplication algorithm this we can specify it like this:
</p>

<pre class="language-javascript">
<code>function mult(x, y) {
  return x * y;
}</code>
</pre>

<p>
We see that the specification using JavaScript is much more clear and shorter than using the natural language. Later in the book primarily JavaScript will be used, but we will keep in mind that the discussed algorithms can actually be expressed using other formal notations. Many Computer Science books go as far as inventing their own "pseudocode" in order to not be dependent on implementation details of a particular programming language. We will not go as far as they do and will happily use JavaScript, hence the name of the book "Algorithms with JavaScript".
</p>

<p>
Another question that we can ask by now are there any computational procedures that are not algorithms? Yes, there are and we will provide examples immediately.
</p>

<p>
First example is an infinite computational procedure which is by given definition not an algorithm:
</p>

<pre class="language-javascript">
<code>function getMaximumNumber() {
  var x = 0;
  while(true) {
    x++;
  }
  return x;
}</code>
</pre>

<p>
From this example we also see that not every computational procedure that can be formally expressed using some notation is an algorithm.
</p>

<p>
Another example of a non-algorithm will be the following division implementation defined on the set of all numbers:
</p>

<pre class="language-javascript">
<code>function divide(x, y) {
  if (y == 0) {
    throw new Error("Cannot divide by zero");
  }
  return x / y;
}</code>
</pre>

<p>
This is not an algorithm because the result is not defined for all the pairs <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
<mstyle>
  <mo>(</mo>
  <mi>x</mi>
  <mo>,</mo>
  <mi>y</mi>
  <mo>)</mo>
</mstyle>
</math> where <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>y</mi></math> is <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>0</mi></math>. However, it is easy to fix this and make the function <i>divide</i> specify an algorithm:
</p>

<pre class="language-javascript">
<code>function divide(x, y) {
  return y == 0 ? Infinity : x / y;
}</code>
</pre>

<p>
In fact in JavaScript returning <i>Infinity</i> when dividing by <i>0</i> is the default behavior so we can just write:
</p>

<pre class="language-javascript">
<code>function divide(x, y) {
  return x / y;
}</code>
</pre>

<p>
And this will be an algorithm, but only given the details of JavaScript engine implementation and the fact that it is possible to divide by <i>0</i> in JavaScript.
</p>

<p>
Now that we are finished with discussing the definition, let's try to take a look at a few more interesting algorithms.
</p>

<h2>Algorithm: finding maximum element</h2>

<p>
Let's try to find a maximum element in an array of elements. The algorithm is still quite simple:
</p>

<div class="highlighted">
<div class="example-title">Finding maximum element</div>
Given an array of or elements which can be empty:
<ol>
  <li>The current maximum is not defined in the beginning</li>
  <li>Take the next element in the array which was not yet taken, to be specific the next such element with the smallest index. If there is no next element (for example, the array is empty) go directly to the step 5.</li>
  <li>If the element is greater than the current maximum or the current maximum is not defined, update the current maximum to be the element</li>
  <li>Go to step 2</li>
  <li>Return maximum element</li>
</ol>
</div>
<div class="artefact-label" href="#1.2">1.2 - Finding maximum element</div>

<p>
The implementation in JavaScript:
</p>

<pre class="language-javascript line-numbers">
<code>function max(elements) {
    var max;

    for (var i = 0; i < elements.length; i++) {
      if (max == undefined || elements[i] > max) {
        max = elements[i];
      }
    }
    return max;
  }</code>
</pre>

<p>
This is in fact an algorithm: it is defined on all the arrays of numbers, finishes in a finite number of steps and can be formally specified. The code is more or less obvious, on the line 2 we declare the maximum and it is  <i>undefined</i> in the beginning. Then we go through all the elements of the array starting with the elements with smaller indexes in lines 4-8 and for each such element <i>elements[i]</i> we compare it to <i>max</i> and if the last is smaller than the current element or <i>undefined</i> we update <i>max</i> to be <i>elements[i]</i>. This corresponds to the algorithm specification given above in <i>1.2</i>.
</p>

<p>
In this case the algorithm is pretty straightforward and no other computational procedures can obviously be better. Also it is quite clear that we should look through all the elements in the array to find a maximum anyway. So, probably we cannot optimize this algorithm further.
</p>

<p>
However, usually the situation is not as clear as this one and we can have several algorithms that can be candidates for solving a particular problem and returning a result. In such a case we would like to choose the best algorithm. The best normally means the one that executes faster and requires less memory.
</p>

<p>
So far, we have not formalized what it means to be faster or more memory-efficient. Now is about time to rectify this and introduce formal means which will allow to compare algorithms to each other. First, let's start with the discussion of <i>time complexity</i>.
</p>

<h2>Time complexity</h2>

<p>
One of such important characteristics that can be used to compare algorithms with each other can be the time it takes to execute a program. In most cases we would like our algorithms to be fast, but what machine do we use to measure the time it takes the algorithm to finish its work on typical input? Should it be a smartphone, a tablet, or even a supercomputer?
</p>

<p>
Let's consider a more real-life metaphor for what we are trying to achieve here. Our situation is a bit like trying to reach point B from point A and having several routes to choose from. Here point A is the input for our algorithms, a route is an algorithm and point B is the output. The time it takes to reach point B corresponds to the execution time of an algorithm.
</p>

<p>
Should we measure the time it takes to drive a car from A to B for each of these roads? What if our car is accidentally loaded more when we drive on some of these roads? Do we then compare the different routes in a fair manner? What if the weather is different and due to the wind we drive slower? Or should we maybe use a bicycle altogether?
</p>

<p>
Clearly we would like to abstract away from all these accidental details related to how we reach point B from point A and compare the routes to each other using only the essential information we need. In this case such essential information can be the length of the route. If we take compare only the lengthes of the different routes we no longer care what road conditions there are, which car we use, and so forth. Of course, not only the length of the route matters, it may also matter whether the route is flat, how many curves it has or whether it goes through a road with no asphalt. But the route length is still a good first approximation.
</p>

<p>
Similarly in the case of algorithms comparing the execution time is also a good first approximation of how to compare algorithms. No doubt can be other characteristics that we would like to compare. One of such characterstics is the amount of memory an algorithm uses when it is executed, in fact, we will consider it just after the discussion of the time complexity. Other characteristics we would like to measure and compare to each other can be the number of assignment or read operations, etc.
</p>

<p>
So how do we go about execution time of the algorithm? How do we abstract it from a particular machine and execution on that machine similarly to our route from A to B metaphor?
</p>

<p>
One approach that we will follow is to count the number of primitive operations performed by an algorithm. By a primitive operation we mean comparing two numbers, remembering some value or referring to some value, etc. Alternatively we could measure the number of steps from the definition 1.1 of an algorithm but steps can be not equivalent in terms of time complexity: some steps can be relatively simple and other can include multiple operations.
</p>

<p>
So by now we agreed to measure the the number of primitive operations and approximate the resulting value as the execution time of algorithm. But what if the number of steps is different for different inputs?
</p>

<p>
For example, an algorithm that tries to find the first position of an element in an array can finish its work both after examining the first element in the input and the last. Here we will not be providing a formal specification of the algorithm in English but just provide the implementation in JavaScript right away. This is still a formal specification that we need according to the definition of an algorithm 1.1.
</p>

<pre class="language-javascript line-numbers with-artefact-label">
<code>function find(elements, toFind) {
  var position = -1;
  var currentIndex = 0;

  while ((currentIndex < elements.length) && (position < 0)) {
    if (elements[currentIndex] == toFind) {
      position = currentIndex;
    }
    currentIndex++;
  }
  return position;
}</code>
</pre>
<div class="artefact-label" href="#1.3">1.3 - Finding element</div>

And a short example of invoking the <i>find</i> function:

<pre class="language-javascript">
<code>var arr = [1, 2, 3, 4, 5];

console.log(find(arr, 3)); //2
console.log(find(arr, 10)); //-1</code>
</pre>

<p>
How do we measure the number of primitive operations for such an algorithm given that it strongly depends on the provided array? The answer to this difficulty can be measuring the average number of primitive operations that can be observed by providing sufficiently large number of different arrays of the given length. In the first approximation and having no further specific information about the possible inputs we can assume that are random.
</p>

<p>
If you are familiar with the Probability Theory, speaking its language, we can define the time complexity as the mean of the number of primitive operations the algorithm performs given a particular distribution of the possible inputs for an algorithm.
</p>

<p>
Now if we try to give the estimation of the time complexity of the algorithm above, first we will count the number of primitive operations.
</p>

<p>
Lines 2, 3 and 12 give one primitive operation each, so this is <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>3</mi></math>, in lines 5 - 11 first we perform one comparison for all the elements except the last one for which we make an additional one, we will count this as <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>k</mi></math> primitive operations where <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>k</mi></math> is the number of steps before we find an element. It is obvious that <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
  <mi>0</mi>
  <mo>&le;</mo>
  <mi>k</mi>
  <mo>&le;</mo>
  <mi>n</mi>
</math>, where <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>n</mi></math> is the length of the array. On each iteration we additionally make one comparison in line 6 and one assignment in line 7 or line 9, this gives us <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
  <mi>3</mi>
  <mo>*</mo>
  <mi>k</mi>
</math> primitive operations for lines 5 - 11 in total. The formula for the time complexity for the case when there is such an element <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>k</mi></math> in the array will be:
</p>

<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>t</mi>
  <mrow>
    <mo>(</mo>
    <mi>k</mi>
    <mo>)</mo>
  </mrow>
  <mo>=</mo>
  <mrow>
    <mi>3</mi>
    <mo>*</mo>
    <mi>k</mi>
    <mo>+</mo>
    <mi>3</mi>
  </mrow>
</math>

<p>
Taking the average by <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>k</mi></math> which is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mfrac>
    <mi>n</mi>
    <mi>2</mi>
  </mfrac>
</math> we obtain the time complexity for the algorithm. In fact it can be represented as a function of the number of elements in the array <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>n</mi></math>:
</p>

<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>t</mi>
  <mrow>
    <mo>(</mo>
    <mi>n</mi>
    <mo>)</mo>
  </mrow>
  <mo>=</mo>
  <mrow>
    <mfrac>
      <mi>3</mi>
      <mi>2</mi>
    </mfrac>
    <mo>*</mo>
    <mi>n</mi>
    <mo>+</mo>
    <mi>3</mi>
  </mrow>
</math>

<p>
Let's now look at the algorithm 1.2 for finding the maximum element. The number of primitive operations that this algorithm will perform also depends on the size of the input array, luckily for us, in this case, it does not depend on what the elements of the array are. In a similar fashion we find the time complexity of the algorithm to be:
</p>

<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>t</mi>
  <mrow>
    <mo>(</mo>
    <mi>n</mi>
    <mo>)</mo>
  </mrow>
  <mo>=</mo>
  <mrow>
    <mi>4</mi>
    <mo>*</mo>
    <mi>n</mi>
    <mo>+</mo>
    <mi>1</mi>
  </mrow>
</math>

<p>
Now with these two examples we can finally give a formal definition of what the time complexity of an algorithm is. First, we can note that in these examples the time complexity was a function of the length of the input array. The length of the input array is here just a particular case of the size of an input. Let's define what the size of the input is formally.
</p>

<div class="highlighted">
<div class="definition-term">Input size</div>
Let's select a function that given an input produces a natural number or zero. The value produced by this function we will call the input size for a given input.
</div>
<div class="artefact-label" href="#1.4">1.4 - Input size</div>

<p>
In our two last examples the functon was length, however, according to the given definition there is considerable freedom in what to choose as the input size, for example, for an array it should not necessarily be the length, it can also be the minimum element or the number of odd elements, etc.
</p>

<div class="highlighted">
<div class="definition-term">Time complexity of algorithm</div>
<p>
Given an algorithm, a set of its possible inputs, and the distribution (relative frequencies) of those values, we define the time complexity of this algorithm as the average number of primitive operations (take value, assign value, compare two values, etc.) it takes the algorithm to complete its work.
</p>
<p>
The function that determines the input size for a given algorithm input is normally selected in such a manner that the time complexity of the algorithm for a given input can be determined only given the size of this input. In other words the time complexity can be expressed as a function of the input size.
</p>
</div>
<div class="artefact-label" href="#1.5">1.5 - Time complexity of algorithm</div>

<p>
In the examples above we found the time complexity of the algorithms for finding an element and finding a maximum element as the functions of the input size. This is normally what we will need to analyze how the time complexity of an algorithm changes given that its input size changes. Traditionally, we are normally interested in how the time complexity changes as the input size grows.
</p>

<p>
Given the definition 1.5 of the time complexity, clearly, if we want to compare the time complexity of two different algorithms then they should have the same set of inputs and input distribution. Otherwise we will be comparing apples to oranges or two functions of single argument with different arguments. As a rule this is not a problem as we normally would like to compare the efficiency and time complexity of algorithms that solve the same problem and therefore share the possible input values. An example of this we will see in this chapter a bit later when we compare two different algorithms for finding all the prime numbers less then a given number.
</p>

<h2>Big O-notation, Theta-notation</h2>

<p>So now we know how to express mathematically the time complexity of an algorithm as a function of the input size. But how do we compare such functions with each other in order to understand what algorithm has a better time complexity?
</p>

<p>
It is quite common to study the behavior of the complexity function when the input size grows larger and larger, that is, in mathematical terms the asymptotic behavior of the time complexity function. The logic behind this is quite straightforward: for small input sizes the execution times for different algorithms solving the same problem are likely also small and roughly can be deemed the same. On the other hand as the input size grows the execution times also normally grows and the difference between the execution times of algorithms also grows.
</p>

<div class="highlighted">
<div class="example-title">Algorithm with decreasing time complexity</div>
A short side note about why the execution time normally grows as the input size grows. It is actually easy to build an algorithm the execution time of which decreases as the input size grows. Not that it will be useful for anything, but quite interesting. The algorithm: given <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>n</mi></math> output the first <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
  <mo>&#x230a;</mo>
  <mfrac>
    <mi>100</mi>
    <mi>n</mi>
  </mfrac>
  <mo>&#x230b;</mo>
</math> odd numbers.
The algorithm is a bit artificial, and normally we select the input size in such a manner that the execution time grows anyway.
</div>
<div class="artefact-label" href="#1.6">1.6 - Finding maximum element</div>

<p>
In order to study how the time complexity function behaves as the input size grows asymptotically to plus infinity we will need to introduce some formal mathematical notation.
</p>

<div class="highlighted">
<div class="definition-term">o-notation</div>
<p>
Given two functions defined for all positive integers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math>, we say that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>o</mi></math> (small 'o') of <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math> and denote this fact as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> if there exists a positive constant <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>C</mi></math> and a sufficiently large positive integer number <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>N</mi></math> such that for all positive integers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mo>n</mo>
  <mi>&ge;</mi>
  <mo>N</mo>
</math> the following inequality is true <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mi>&ge;</mi>
<mi>C</mi>
<mo>*</mo>
<mi>g</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math>
</p>
<p>
That is, for large enough arguments the values of the first function which is the 'o' of the second function are larger than the values of the second function multiplied by some constant.
</p>
</div>
<div class="artefact-label" href="#1.7">1.7 - o-notation</div>

<div class="highlighted">
<div class="definition-term">O-notation</div>
<p>
Given two functions defined for all positive integers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math>, we say that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>O</mi></math> (big 'O') of <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math> and denote this fact as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> if and only if <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>.
</p>
<p>
That is, for large enough arguments the values of the first function which is the 'O' of the second function are smaller than the values of the second function multiplied by some constant.
</p>
</div>
<div class="artefact-label" href="#1.8">1.8 - O-notation</div>

<div class="highlighted">
<div class="definition-term">&#920;-notation</div>
<p>
Given two functions defined for all positive integers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math>, we say that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>&#920;</mi></math> (theta) of <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math> and denote this fact as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920;</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> if and only if <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>.
</p>
<p>
That is, for large enough arguments the values of the first function which is the '&#920' of the second function are smaller than the values of the second function multiplied by some constant and at the same time larger than the values of the second function multiplied by some other constant.
</p>
<p>
In this case we also say that both functions are asymptotically equivalent.
</p>
</div>
<div class="artefact-label" href="#1.9">1.9 - &#920;-notation</div>

Let's now prove quickly a simple theorem given the above definition and justify why in fact we say that both functions are asymptotically equivalent if one of them is a '&#920' of another.

<div class="highlighted">
<div class="theorem-title">Equivalency of &#920-notation</div>
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> if and only if <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>.
</p>

<p>
The equation above allows us to say that the functions <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math> are equivalent in case one of them is a '&#920' of another, in fact it does not matter which one.
</p>
</div>
<div class="artefact-label" href="#1.10">1.10 - Equivalency of &#920-notation</div>

<p>
<div class="section-label">Proof:</div>
</p>

<p>
For proving the theorem it is enough to show that from <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> it follows that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. Because once we prove this fact we can just exchange <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math> and see that from <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> it also follows that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>. And those two observations will prove the theorem, since the first one proves 'only if' and the second one 'if'.
</p>

<p>
To finish the proof of the theorem let's now prove that from <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> it follows that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. For this we will first look at the definition 1.9 of &#920-notation. Given that from <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> by definition this means that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>.
But at the same time according to the definition 1.8 of O-notation <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> is the same as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>, and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> is the same as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. At this point we have both <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and by the definition 1.9 of &#920-notation this just means that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. This finishes the proof of the theorem &#x25a0;
</p>

<p>
<div class="section-label">Note</div>
</p>
<p>
In our definitions and when we talk about asymptotic behavior we always assume that the argument of the functions in question is growing towards positive infinity. In our case this covers the behavior of the input size and the fact that normally the time complexity grows as the input size grows and we want to compare the time complexities with each other when they are large. However, the given definitions of o, O and &#920 can be generalized and be relevant for functions that accept arguments other than positive integers and for the arguments approaching values other than plus infinity. However, for our needs in this book this is a bit excessive and we will just use the simplified definitions given above which will be more than enough for the algorithms we are going to consider later.
</p>

<div class="highlighted">
<div class="theorem-title">Substitution with &#920-equivalent functions</div>
In expressions using asymptotic notation we can substitute functions with other functions that are &#920-equivalent to the original functions. More formally:
<ol>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
</ol>

<p>
These observations allow us to freely substitute functions with their &#920-equivalent functions which may allow us to potentially simplify expressions that use asymptotic notation.
</p>
</div>
<div class="artefact-label" href="#1.11">1.11 - Substitution with &#920-equivalent functions</div>

<p>
<div class="section-label">Proof:</div>
</p>

<p>
  Let's prove all the points stated above starting with the first one.
</p>

<p>
  <ol>
    <li>
<p>
We know that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. According to the definition 1.9 of &#920-notation this means that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. Then by definition 1.7 of o-notation we can find constants <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
  <mi>C</mi>
  <mi>1</mi>
</msub>
<mo>,</mo>
<msub>
  <mi>C</mi>
  <mi>2</mi>
</msub>
</math> and natural numbers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
  <mi>N</mi>
  <mi>1</mi>
</msub>
<mo>,</mo>
<msub>
  <mi>N</mi>
  <mi>2</mi>
</msub>
</math> such that for all natural <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>&ge;</mo>
<msub>
  <mi>N</mi>
  <mi>1</mi>
</msub>
</math> we have <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>&ge;</mo>
<msub>
  <mi>C</mi>
  <mi>1</mi>
</msub>
<mo>*</mo>
<mi>g</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math> and for all natural <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>&ge;</mo>
<msub>
  <mi>N</mi>
  <mi>2</mi>
</msub>
</math> we have <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>&ge;</mo>
<msub>
  <mi>C</mi>
  <mi>2</mi>
</msub>
<mo>*</mo>
<mi>f</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math>. Then if we take <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>N</mi>
<mo>=</mo>
<mo>max</mo>
<mo>(</mo>
<msub>
  <mi>N</mi>
  <mi>1</mi>
</msub>
<mo>,</mo>
<msub>
  <mi>N</mi>
  <mi>2</mi>
</msub>
<mo>)</mo>
</math> we see for all natural <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>&ge;</mo>
<mi>N</mi>
</math> that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>&ge;</mo>
<msub>
  <mi>C</mi>
  <mi>2</mi>
</msub>
<mo>*</mo>
<mi>f</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>&ge;</mo>
<msub>
  <mi>C</mi>
  <mi>2</mi>
</msub>
<mo>*</mo>
<msub>
  <mi>C</mi>
  <mi>1</mi>
</msub>
<mo>*</mo>
<mi>g</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math>. If we take <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>C</mi>
<mo>=</mo>
<msub>
  <mi>C</mi>
  <mi>1</mi>
</msub>
<mo>*</mo>
<msub>
  <mi>C</mi>
  <mi>2</mi>
</msub>
</math> then we see that by definition 1.7 of o-notation we have <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> which is precisely what we wanted to prove.
</p>
<p>
In the process of proving the first point we also proved the following fact which will be useful for proving the second point: if <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>. We can call this fact transitivity of o.
</p>
    </li>
    <li>
      Proof is done in a similar fashion. Given that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> by definition 1.9 of &#920-notation we have <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, which according to the definition of 1.8 of O-notation is the same as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>. Now combining this with <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> we see according to the transitivity of o that was proved above that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> which is exactly what we wanted to prove.
    </li>
    <li>
      Given that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, which according to the definition 1.8 of O-notation is the same as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and having <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> according to already proven point 2 we see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> which again according to the definition 1.8 of O-notation is the same as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> which is what we wanted to prove.
    </li>
    <li>
      Similar to the previously proven point we have <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> which allows us to apply the first point of the theorem and see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> which we wanted to prove.
    </li>
    <li>
      According to the definition 1.9 of &#920-notation <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, then combining this with <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and the proven points 1 and 3 of the present theorem we see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> which by definition means <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and the point is proven.
    </li>
    <li>
      In a fashion similar to the previous point, we apply the definition of &#920-notation twice and the proven points 2 and 4 of the present theorem to prove that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> &#x25a0;
    </li>
  </ol>
</p>

<div class="highlighted no-artefact-label">
  <div class="note-title">Using equality = in asymptotic notation</div>
<p>
Now it is time for a quick necessary note on the terminology and notation. Up until this moment we were writing <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> meaning that f belongs to a set of functions that are <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>. In no way did we imply with the = sign that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> is equal to that set of functions. In fact it would be much more sensible to write <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>&isin;</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, meaning <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> belongs to the set of functions that are <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> instead of <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>.
</p>
<p>
For historical reasons we will continue to use the former notation and write informally that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, at the same time understanding that the equality = here is a special kind of equality, more like belonging to a set.
</p>
<p>
Now, if we informally write later something like <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
<mo>+</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> it does not mean that we take a set of functions that are <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and add it to itself. There is nothing strange in adding two sets, it may just mean, for example, taking the union of two sets: a new set that contains all the elements of the original sets. But in this case everything is much simpler: we are just looking at <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>+</mo>
<mi>h</mi>
</math> where <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>.
</p>
</div>

<p>
Now let's formulate a few additional properties of o, O, and &#920 that will be useful for us when we will be estimating the time complexity of different algorithms. Proving the following theorems is left to the reader as an exercise.
</p>

<div class="highlighted">
<div class="theorem-title">Arithmetic operations and asymptotic notation</div>
<ol>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
</math> is a constant, then <math>
<mi>f</mi>
<mo>+</mo>
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
<mo>*</mo>
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
</math> is a constant, then <math>
<mi>f</mi>
<mo>+</mo>
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
<mo>*</mo>
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
</math> is a constant, then <math>
<mi>f</mi>
<mo>+</mo>
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
<mo>*</mo>
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
</ol>
</p>

<p>
The theorem essentially says that if add and multiply by a constant then the asymptotic properties of functions are preserved.
</p>
</div>
<div class="artefact-label" href="#1.12">1.12 - Arithmetic operations and asymptotic notation</div>

<div class="highlighted">
<div class="theorem-title">Transitivity of asymptotic notation</div>
<ol>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> then
<math>
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>g</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> then
<math>
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> then
<math>
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
</ol>
</p>

<p>
Essentially the asymptotic notation behaves a like the normal comparison operators and equality: <math>
<mi>o</mi>
</math> is like <math>
<mo>&ge;</mo>
</math>, <math>
<mi>O</mi>
</math> is like <math>
<mo>&le;</mo>
</math> and <math>
<mi>&#920</mi>
</math> is like <math>
<mo>=</mo>
</math>. And we know that from, for example, <math>
<mi>x</mi>
<mo>&ge;</mo>
<mi>y</mi>
</math>, <math>
<mi>y</mi>
<mo>&ge;</mo>
<mi>z</mi>
</math> follows that <math>
<mi>x</mi>
<mo>&ge;</mo>
<mi>z</mi>
</math>.
</p>
</div>
<div class="artefact-label" href="#1.12">1.13 - Transitivity of asymptotic notation</div>

<div class="highlighted">
<div class="theorem-title">Preserving &#920-behavior</div>
If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>,
<math>
<mi>g</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>, <math>
<mi>g</mi>
<mo>&ge;</mo>
<mi>0</mi>
</math> then
<math>
<mi>f</mi>
<mo>+</mo>
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
</p>

<p>
This means that when dealing with asymptotic notation we can simplify expressions by disregarding the O part and leaving the &#920 part, informally we can say that "&#920 plus O is still &#920".
</p>
</div>
<div class="artefact-label" href="#1.14">1.14 - Preserving &#920-behavior</div>

<p>
Based on the theorems above we can now reason more easily about the asymptotic notation and simplify expressions in order to get rid of the unnecessary details.
</p>

<p>
That was quite a bit of formalization, and if you feel a bit confused, don't despair, all will become much clearer after a few simple examples. But even if you still do not grasp the mathematics behind the definition then hopefully you will have at least some intuitive feeling of what the asymptotic notation actually means.
</p>

<div class="highlighted no-artefact-label">
  <div class="example-title">o-notation, O-notation</div>
<ol>
<li>
<div>
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msup>
  <mi>n</mi>
  <mn>2</mn>
</msup>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mrow>
  <mi>n</mi>
</mrow>
<mo>)</mo>
</math>
and
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mrow>
  <msup>
    <mi>n</mi>
    <mn>2</mn>
  </msup>
</mrow>
<mo>)</mo>
</math>
</div>

This is obvious according to the given definition 1.7 of o-notation, we just need to find 
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>C</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>N</mi></math> from the definition. But this is relatively easy in this case, we just take <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>C</mi>
  <mo>=</mo>
  <mi>1</mi>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>N</mi>
  <mo>=</mo>
  <mi>2</mi>
</math> we see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msup>
  <mi>n</mi>
  <mn>2</mn>
</msup>
<mo>&ge;</mo>
<mi>n</mi>
</math> and then by definition <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msup>
  <mi>n</mi>
  <mn>2</mn>
</msup>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mrow>
  <mi>n</mi>
</mrow>
<mo>)</mo>
</math>. But even intuitively it is clear that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msup>
  <mi>n</mi>
  <mn>2</mn>
</msup>
</math> at some point becomes larger than <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>n</mi>
</math>. Then by definition 1.8 of O-notation we also immediately see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mrow>
  <msup>
    <mi>n</mi>
    <mn>2</mn>
  </msup>
</mrow>
<mo>)</mo>
</math>.
</li>
<li>
  <div>
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mrow>
  <mi>8</mi>
</mrow>
<mo>)</mo>
</math>
and
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>8</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mrow>
  <mi>n</mi>
</mrow>
<mo>)</mo>
</math>
</div>
<p>
We just again note that we take <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>C</mi>
  <mo>=</mo>
  <mi>1</mi>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>N</mi>
  <mo>=</mo>
  <mi>8</mi>
</math> or even <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>C</mi>
  <mo>=</mo>
  <mfrac>
    <mo>1</mo>
    <mo>2</mo>
  </mfrac>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>N</mi>
  <mo>=</mo>
  <mi>4</mi>
</math>, or <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>C</mi>
  <mo>=</mo>
  <mi>8</mi>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>N</mi>
  <mo>=</mo>
  <mfrac>
    <mo>1</mo>
    <mo>8</mo>
  </mfrac>
</math>, and we also see that there is a considerable amount of freedom in choosing the constants.
</p>
<p>
According to the theorem 1.11 about substituting functions with their &#920-equivalent functions and noting that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>8</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mrow>
  <mi>1</mi>
</mrow>
<mo>)</mo>
</math> we also see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mrow>
  <mi>1</mi>
</mrow>
<mo>)</mo>
</math>
and
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>1</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mrow>
  <mi>n</mi>
</mrow>
<mo>)</mo>
</math>.
</p>
</li>
<li>
TODO: Example where there are multiple components, like n^2, n^3, n^4
</li>
</ul>

<p>
  
</p>
</div>

TODO: Provide examples with functions.

TODO:

Discuss that the argument values can not only be increasing but in fact be reaching any chosen limit.

Discuss that the O notation may in fact be irrelevant in case we are dealing with relatively small inputs like arrays of no more than 10 elements, etc.

If we are doing some optimization for small or medium inputs we should compare the function values, not just the asymptotic behavior.

<h2>Storage complexity</h2>

TODO:

Tradeoff speed vs. storage.

<h2>Eratosthenes sieve</h2>

TODO:

<h2>Euclidus algorithm</h2>

TODO:

<p>Here goes the contents and some JavaScript code</p>

<pre class="line-numbers language-javascript">
<code>function max(elements) {
  var max;

  for (var i = 0; i < elements.length; i++) {
    if (max == undefined || elements[i] > max) {
      max = elements[i];
    }
  }
  return max;
}</code>
</pre>

<p>
And here goes an illustration:
</p>

<!-- TODO: Use Handlebars template to render such thing as an illustration? -->

<div class="medium illustration">
  <img src="chapters/chapter1/svg/1.1.eratosthenes.sieve.svg" title="Sieve of Eratosthenes up to 15"/>
  <div class="artefact-label">1.1 - Sieve of Eratosthenes up to 15</div>
</div>

<p>
And after that we can use an inline formula

<math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
  <msup>
    <mi>e</mi>
    <mrow>
      <mn>2</mn>
      <mi>x</mi>
      <mo>+</mo>
      <mn>1</mn>
    </mrow>
  </msup>
</math>

</p>