<h1>
<a name="chapter1" class="anchor" href="#chapter1"><span class="octicon octicon-link"></span></a>Chapter 1 - Algorithms</h1>

<!--
TODO: Finding max element
TODO: Eratosphenus sieve
TODO: Finding gcd

Excercises:
TODO: Determining if a string is a palindrome
TODO: Finding all the perfect numbers less than given number (sum of all positive dividers is equal to number)
TODO: Program that solves a quadratic equation, input three coefficients, output the found roots
-->

<p>In this chapter we discuss what is an algorithm, time complexity, storage complexity and provide a few examples of algorithms.
</p>

<h2>What is an algorithm?</h2>

<p>
Let's first start with a discussion of what an algorithm is. Intuitively the definition is more or less clear, we are talking about some formal way to describe a computational procedure. According to the Merriam-Webster dictionary algorithm is "a set of steps that are followed in order to solve a mathematical problem or to complete a computer process".
</p>

<p>
Still this is probably not formal enough. How do we choose the next steps from the set of steps? Should we stop eventually? What is the result of an execution of an algorithm? There can be given many formal definitions of what constitutes an algorithm, however, at this point in the book, without introducing the abstract models of computation and what computation is, we will just give the following definition.
</p>

<div class="highlighted">
<div class="definition-term">Algorithm</div>
Set of computational steps which specifies a formal computational procedure and has the following properties:
<ol class="lower-alpha">
  <li>After each step is completed the next step is unambiguously defined or the algorithm stops its execution if there are no more steps left</li>
  <li>It is defined on a set of inputs and for each input it stops after a finite number of steps</li>
  <li>When it stops it produces a result which we call its output</li>
  <li>Its steps and their order of execution can be formally and unambiguously specified using some language or notation</li>
</ol>
</div>
<div class="artefact-label" href="#1.1">1.1 - Algorithm</div>

Algorithms can be expressed in a variety of ways. We can even specify the execution steps using the normal human language.
Let's provide a few simple examples. First trivial example will be multiplying two numbers.

<div class="highlighted no-artefact-label">
<div class="example-title">Algorithm of integer number multiplication.</div>
Steps:
<ol>
<li>Given two integer numbers multiply them and return the result</li>
</ol>
</div>

<p>
All the points from the definition of the algorithm are satisfied. There is only one step, after this step algorithm stops, the step is formally specified, all the integer numbers are valid inputs and a valid result will be produced for them. If we denote the algorithm for multiplication as <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>mult</mi></math> then, for example, <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
<mstyle>
  <mi>mult</mi>
    <mrow>
      <mo>(</mo>
      <mi>2</mi>
      <mo>,</mo>
      <mi>5</mi>
      <mo>)</mo>
    </mrow>
  <mo>=</mo>
  <mi>10</mi>
</mstyle>
</math> and we can formally specify the algorithm as follows <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
<mstyle>
  <mi>mult</mi>
    <mrow>
      <mo>(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>y</mi>
      <mo>)</mo>
    </mrow>
  <mo>=</mo>
  <mi>x</mi>
  <mo>*</mo>
  <mi>y</mi>
</mstyle>
</math>.
</p>

<p>
So far while talking about algorithms we encountered no JavaScript or any other programming language notation. This is quite intentional since we now clearly see that the notion of an algorithm is more of a mathematical one and it is quite abstract. Of course we can express any algorithm using JavaScript but this will be just one of the possible formal representations, in this case also executable by a JavaScript engine.
</p>

<p>
A careful reader might be a bit puzzled by our confidence at this point. How can we state that any algorithm can be expressed using JavaScript? Can this be in fact proven given the definition of an algorithm we gave earlier? Is JavaScript in fact powerful enough to express all the algorithms there can be? It turns out it is, but we will leave this statement without any proof until the very end of the book where we will discuss abstract models of computation and give even more formal and strict definition of an algorithm.
</p>

<p>
Let's look again at the definition 1.1 of algorithm and its part that states that we should be able to specify the computational procedure formally. Now it is more or less clear why we require this property from an algorithm. Then we can use a formal language such as JavaScript to specify the algorithm of our interest and execute this formal specification by using a machine such as a laptop or even smartphone. For the number multiplication algorithm this we can specify it like this:
</p>

<pre class="language-javascript">
<code>function mult(x, y) {
  return x * y;
}</code>
</pre>

<p>
We see that the specification using JavaScript is much more clear and shorter than using the natural language. Later in the book primarily JavaScript will be used, but we will keep in mind that the discussed algorithms can actually be expressed using other formal notations. Many Computer Science books go as far as inventing their own "pseudocode" in order to not be dependent on implementation details of a particular programming language. We will not go as far as they do and will happily use JavaScript, hence the name of the book "Algorithms with JavaScript".
</p>

<p>
Another question that we can ask by now are there any computational procedures that are not algorithms? Yes, there are and we will provide examples immediately.
</p>

<p>
First example is an infinite computational procedure which is by given definition not an algorithm:
</p>

<pre class="language-javascript">
<code>function getMaximumNumber() {
  var x = 0;
  while(true) {
    x++;
  }
  return x;
}</code>
</pre>

<p>
From this example we also see that not every computational procedure that can be formally expressed using some notation is an algorithm.
</p>

<p>
Another example of a non-algorithm will be the following division implementation defined on the set of all numbers:
</p>

<pre class="language-javascript">
<code>function divide(x, y) {
  if (y == 0) {
    throw new Error("Cannot divide by zero");
  }
  return x / y;
}</code>
</pre>

<p>
This is not an algorithm because the result is not defined for all the pairs <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
<mstyle>
  <mo>(</mo>
  <mi>x</mi>
  <mo>,</mo>
  <mi>y</mi>
  <mo>)</mo>
</mstyle>
</math> where <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>y</mi></math> is <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>0</mi></math>. However, it is easy to fix this and make the function <i>divide</i> specify an algorithm:
</p>

<pre class="language-javascript">
<code>function divide(x, y) {
  return y == 0 ? Infinity : x / y;
}</code>
</pre>

<p>
In fact in JavaScript returning <i>Infinity</i> when dividing by <i>0</i> is the default behavior so we can just write:
</p>

<pre class="language-javascript">
<code>function divide(x, y) {
  return x / y;
}</code>
</pre>

<p>
And this will be an algorithm, but only given the details of JavaScript engine implementation and the fact that it is possible to divide by <i>0</i> in JavaScript.
</p>

<p>
Now that we are finished with discussing the definition, let's try to take a look at a few more interesting algorithms.
</p>

<h2>Algorithm: finding maximum element</h2>

<p>
Let's try to find a maximum element in an array of elements. The algorithm is still quite simple:
</p>

<div class="highlighted">
<div class="example-title">Finding maximum element</div>
Given an array of or elements which can be empty:
<ol>
  <li>The current maximum is not defined in the beginning</li>
  <li>Take the next element in the array which was not yet taken, to be specific the next such element with the smallest index. If there is no next element (for example, the array is empty) go directly to the step 5.</li>
  <li>If the element is greater than the current maximum or the current maximum is not defined, update the current maximum to be the element</li>
  <li>Go to step 2</li>
  <li>Return maximum element</li>
</ol>
</div>
<div class="artefact-label" href="#1.2">1.2 - Finding maximum element</div>

<p>
The implementation in JavaScript:
</p>

<pre class="language-javascript line-numbers">
<code>function max(elements) {
    var max;

    for (var i = 0; i < elements.length; i++) {
      if (max == undefined || elements[i] > max) {
        max = elements[i];
      }
    }
    return max;
  }</code>
</pre>

<p>
This is in fact an algorithm: it is defined on all the arrays of numbers, finishes in a finite number of steps and can be formally specified. The code is more or less obvious, on the line 2 we declare the maximum and it is  <i>undefined</i> in the beginning. Then we go through all the elements of the array starting with the elements with smaller indexes in lines 4-8 and for each such element <i>elements[i]</i> we compare it to <i>max</i> and if the last is smaller than the current element or <i>undefined</i> we update <i>max</i> to be <i>elements[i]</i>. This corresponds to the algorithm specification given above in <i>1.2</i>.
</p>

<p>
In this case the algorithm is pretty straightforward and no other computational procedures can obviously be better. Also it is quite clear that we should look through all the elements in the array to find a maximum anyway. So, probably we cannot optimize this algorithm further.
</p>

<p>
However, usually the situation is not as clear as this one and we can have several algorithms that can be candidates for solving a particular problem and returning a result. In such a case we would like to choose the best algorithm. The best normally means the one that executes faster and requires less memory.
</p>

<p>
So far, we have not formalized what it means to be faster or more memory-efficient. Now is about time to rectify this and introduce formal means which will allow to compare algorithms to each other. First, let's start with the discussion of <i>time complexity</i>.
</p>

<h2>Time complexity</h2>

<p>
One of such important characteristics that can be used to compare algorithms with each other can be the time it takes to execute a program. In most cases we would like our algorithms to be fast, but what machine do we use to measure the time it takes the algorithm to finish its work on typical input? Should it be a smartphone, a tablet, or even a supercomputer?
</p>

<p>
Let's consider a more real-life metaphor for what we are trying to achieve here. Our situation is a bit like trying to reach point B from point A and having several routes to choose from. Here point A is the input for our algorithms, a route is an algorithm and point B is the output. The time it takes to reach point B corresponds to the execution time of an algorithm.
</p>

<p>
Should we measure the time it takes to drive a car from A to B for each of these roads? What if our car is accidentally loaded more when we drive on some of these roads? Do we then compare the different routes in a fair manner? What if the weather is different and due to the wind we drive slower? Or should we maybe use a bicycle altogether?
</p>

<p>
Clearly we would like to abstract away from all these accidental details related to how we reach point B from point A and compare the routes to each other using only the essential information we need. In this case such essential information can be the length of the route. If we take compare only the lengthes of the different routes we no longer care what road conditions there are, which car we use, and so forth. Of course, not only the length of the route matters, it may also matter whether the route is flat, how many curves it has or whether it goes through a road with no asphalt. But the route length is still a good first approximation.
</p>

<p>
Similarly in the case of algorithms comparing the execution time is also a good first approximation of how to compare algorithms. No doubt can be other characteristics that we would like to compare. One of such characterstics is the amount of memory an algorithm uses when it is executed, in fact, we will consider it just after the discussion of the time complexity. Other characteristics we would like to measure and compare to each other can be the number of assignment or read operations, etc.
</p>

<p>
So how do we go about execution time of the algorithm? How do we abstract it from a particular machine and execution on that machine similarly to our route from A to B metaphor?
</p>

<p>
One approach that we will follow is to count the number of primitive operations performed by an algorithm. By a primitive operation we mean comparing two numbers, remembering some value or referring to some value, etc. Alternatively we could measure the number of steps from the definition 1.1 of an algorithm but steps can be not equivalent in terms of time complexity: some steps can be relatively simple and other can include multiple operations.
</p>

<p>
So by now we agreed to measure the the number of primitive operations and approximate the resulting value as the execution time of algorithm. But what if the number of steps is different for different inputs?
</p>

<p>
For example, an algorithm that tries to find the first position of an element in an array can finish its work both after examining the first element in the input and the last. Here we will not be providing a formal specification of the algorithm in English but just provide the implementation in JavaScript right away. This is still a formal specification that we need according to the definition of an algorithm 1.1.
</p>

<pre class="language-javascript line-numbers with-artefact-label">
<code>function find(elements, toFind) {
  var position = -1;
  var currentIndex = 0;

  while ((currentIndex < elements.length) && (position < 0)) {
    if (elements[currentIndex] == toFind) {
      position = currentIndex;
    }
    currentIndex++;
  }
  return position;
}</code>
</pre>
<div class="artefact-label" href="#1.3">1.3 - Finding element</div>

And a short example of invoking the <i>find</i> function:

<pre class="language-javascript">
<code>var arr = [1, 2, 3, 4, 5];

console.log(find(arr, 3)); //2
console.log(find(arr, 10)); //-1</code>
</pre>

<p>
How do we measure the number of primitive operations for such an algorithm given that it strongly depends on the provided array? The answer to this difficulty can be measuring the average number of primitive operations that can be observed by providing sufficiently large number of different arrays of the given length. In the first approximation and having no further specific information about the possible inputs we can assume that are random.
</p>

<p>
If you are familiar with the Probability Theory, speaking its language, we can define the time complexity as the mean of the number of primitive operations the algorithm performs given a particular distribution of the possible inputs for an algorithm.
</p>

<p>
Now if we try to give the estimation of the time complexity of the algorithm above, first we will count the number of primitive operations.
</p>

<p>
Lines 2, 3 and 12 give one primitive operation each, so this is <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>3</mi></math>, in lines 5 - 11 first we perform one comparison for all the elements except the last one for which we make an additional one, we will count this as <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>k</mi></math> primitive operations where <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>k</mi></math> is the number of steps before we find an element. It is obvious that <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
  <mi>0</mi>
  <mo>&le;</mo>
  <mi>k</mi>
  <mo>&le;</mo>
  <mi>n</mi>
</math>, where <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>n</mi></math> is the length of the array. On each iteration we additionally make one comparison in line 6 and one assignment in line 7 or line 9, this gives us <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
  <mi>3</mi>
  <mo>*</mo>
  <mi>k</mi>
</math> primitive operations for lines 5 - 11 in total. The formula for the time complexity for the case when there is such an element <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>k</mi></math> in the array will be:
</p>

<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>t</mi>
  <mrow>
    <mo>(</mo>
    <mi>k</mi>
    <mo>)</mo>
  </mrow>
  <mo>=</mo>
  <mrow>
    <mi>3</mi>
    <mo>*</mo>
    <mi>k</mi>
    <mo>+</mo>
    <mi>3</mi>
  </mrow>
</math>

<p>
Taking the average by <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>k</mi></math> which is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mfrac>
    <mi>n</mi>
    <mi>2</mi>
  </mfrac>
</math> we obtain the time complexity for the algorithm. In fact it can be represented as a function of the number of elements in the array <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>n</mi></math>:
</p>

<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>t</mi>
  <mrow>
    <mo>(</mo>
    <mi>n</mi>
    <mo>)</mo>
  </mrow>
  <mo>=</mo>
  <mrow>
    <mfrac>
      <mi>3</mi>
      <mi>2</mi>
    </mfrac>
    <mo>*</mo>
    <mi>n</mi>
    <mo>+</mo>
    <mi>3</mi>
  </mrow>
</math>

<p>
Let's now look at the algorithm 1.2 for finding the maximum element. The number of primitive operations that this algorithm will perform also depends on the size of the input array, luckily for us, in this case, it does not depend on what the elements of the array are. In a similar fashion we find the time complexity of the algorithm to be:
</p>

<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>t</mi>
  <mrow>
    <mo>(</mo>
    <mi>n</mi>
    <mo>)</mo>
  </mrow>
  <mo>=</mo>
  <mrow>
    <mi>4</mi>
    <mo>*</mo>
    <mi>n</mi>
    <mo>+</mo>
    <mi>1</mi>
  </mrow>
</math>

<p>
Now with these two examples we can finally give a formal definition of what the time complexity of an algorithm is. First, we can note that in these examples the time complexity was a function of the length of the input array. The length of the input array is here just a particular case of the size of an input. Let's define what the size of the input is formally.
</p>

<div class="highlighted">
<div class="definition-term">Input size</div>
Let's select a function that given an input produces a natural number or zero. The value produced by this function we will call the input size for a given input.
</div>
<div class="artefact-label" href="#1.4">1.4 - Input size</div>

<p>
In our two last examples the functon was length, however, according to the given definition there is considerable freedom in what to choose as the input size, for example, for an array it should not necessarily be the length, it can also be the minimum element or the number of odd elements, etc.
</p>

<div class="highlighted">
<div class="definition-term">Time complexity of algorithm</div>
<p>
Given an algorithm, a set of its possible inputs, and the distribution (relative frequencies) of the inputs, we define the time complexity of this algorithm as the average number of primitive operations (take value, assign value, compare two values, etc.) it takes the algorithm to complete its work.
</p>
<p>
The function that determines the input size for a given algorithm input is normally selected in such a manner that the time complexity of the algorithm for a given input can be determined only given the size of this input. In other words the time complexity can be expressed as a function of the input size.
</p>
</div>
<div class="artefact-label" href="#1.5">1.5 - Time complexity of algorithm</div>

<p>
In the examples above we found the time complexity of the algorithms for finding an element and finding a maximum element as the functions of the input size. This is normally what we will need to analyze how the time complexity of an algorithm changes given that its input size changes. Traditionally, we are normally interested in how the time complexity changes as the input size grows.
</p>

<p>
Given the definition 1.5 of the time complexity, clearly, if we want to compare the time complexity of two different algorithms then they should have the same set of inputs and input distribution. Otherwise we will be comparing apples to oranges or two functions of single argument with different arguments. As a rule this is not a problem as we normally would like to compare the efficiency and time complexity of algorithms that solve the same problem and therefore share the possible input values. An example of this we will see in this chapter a bit later when we compare two different algorithms for finding all the prime numbers less then a given number.
</p>

<h2>Asymptotic notation</h2>

<p>So now we know how to express mathematically the time complexity of an algorithm as a function of the input size. But how do we compare such functions with each other in order to understand what algorithm has a better time complexity?
</p>

<p>
It is quite common to study the behavior of the complexity function when the input size grows larger and larger, that is, in mathematical terms the asymptotic behavior of the time complexity function. The logic behind this is quite straightforward: for small input sizes the execution times for different algorithms solving the same problem are likely also small and roughly can be deemed the same. On the other hand as the input size grows the execution times also normally grows and the difference between the execution times of algorithms also grows.
</p>

<div class="highlighted">
<div class="example-title">Algorithm with decreasing time complexity</div>
A short side note about why the execution time normally grows as the input size grows. It is actually easy to build an algorithm the execution time of which decreases as the input size grows. Not that it will be useful for anything, but quite interesting. The algorithm: given <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math"><mi>n</mi></math> output the first <math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
  <mo>&#x230a;</mo>
  <mfrac>
    <mi>100</mi>
    <mi>n</mi>
  </mfrac>
  <mo>&#x230b;</mo>
</math> odd numbers.
The algorithm is a bit artificial, and normally we select the input size in such a manner that the execution time grows anyway.
</div>
<div class="artefact-label" href="#1.6">1.6 - Finding maximum element</div>

<p>
In order to study how the time complexity function behaves as the input size grows asymptotically to plus infinity we will need to introduce some formal mathematical notation.
</p>

<div class="highlighted">
<div class="definition-term">o-notation</div>
<p>
Given two functions of single argument defined for all positive integers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math>, we say that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>o</mi></math> (small 'o') of <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math> and denote this fact as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> if there exists a positive constant <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>C</mi></math> and a sufficiently large positive integer number <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>N</mi></math> such that for all positive integers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mo>n</mo>
  <mi>&ge;</mi>
  <mo>N</mo>
</math> the following inequality is true <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mi>&ge;</mi>
<mi>C</mi>
<mo>*</mo>
<mi>g</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math>
</p>
<p>
That is, for large enough arguments the values of the first function which is the 'o' of the second function are larger than the values of the second function multiplied by some constant.
</p>
</div>
<div class="artefact-label" href="#1.7">1.7 - o-notation</div>

<div class="highlighted">
<div class="definition-term">O-notation</div>
<p>
Given two functions of single argument defined for all positive integers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math>, we say that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>O</mi></math> (big 'O') of <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math> and denote this fact as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> if and only if <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>.
</p>
<p>
That is, for large enough arguments the values of the first function which is the 'O' of the second function are smaller than the values of the second function multiplied by some constant.
</p>
</div>
<div class="artefact-label" href="#1.8">1.8 - O-notation</div>

<div class="highlighted">
<div class="definition-term">&#920;-notation</div>
<p>
Given two functions of single argument defined for all positive integers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math>, we say that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>&#920;</mi></math> (theta) of <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math> and denote this fact as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920;</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> if and only if <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>.
</p>
<p>
That is, for large enough arguments the values of the first function which is the '&#920' of the second function are smaller than the values of the second function multiplied by some constant and at the same time larger than the values of the second function multiplied by some other constant.
</p>
<p>
In this case we also say that both functions are asymptotically equivalent.
</p>
</div>
<div class="artefact-label" href="#1.9">1.9 - &#920;-notation</div>

Let's now prove quickly a simple theorem given the above definition and justify why in fact we say that both functions are asymptotically equivalent if one of them is a '&#920' of another.

<div class="highlighted">
<div class="theorem-title">Equivalency of &#920-notation</div>
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> if and only if <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>.
</p>

<p>
The equation above allows us to say that the functions <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math> are equivalent in case one of them is a '&#920' of another, in fact it does not matter which one.
</p>
</div>
<div class="artefact-label" href="#1.10">1.10 - Equivalency of &#920-notation</div>

<p>
<div class="section-label">Proof:</div>
</p>

<p>
For proving the theorem it is enough to show that from <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> it follows that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. Because once we prove this fact we can just exchange <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>g</mi></math> and see that from <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> it also follows that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>. And those two observations will prove the theorem, since the first one proves 'only if' and the second one 'if'.
</p>

<p>
To finish the proof of the theorem let's now prove that from <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> it follows that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. For this we will first look at the definition 1.9 of &#920-notation. Given that from <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> by definition this means that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>.
But at the same time according to the definition 1.8 of O-notation <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> is the same as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>, and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> is the same as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. At this point we have both <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and by the definition 1.9 of &#920-notation this just means that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. This finishes the proof of the theorem &#x25a0;
</p>

<p>
<div class="section-label">Note</div>
</p>
<p>
In our definitions and when we talk about asymptotic behavior we always assume that the argument of the functions in question is growing towards positive infinity. In our case this covers the behavior of the input size and the fact that normally the time complexity grows as the input size grows and we want to compare the time complexities with each other when they are large. However, the given definitions of o, O and &#920 can be generalized and be relevant for functions that accept arguments other than positive integers and for the arguments approaching values other than plus infinity. However, for our needs in this book this is a bit excessive and we will just use the simplified definitions given above which will be more than enough for the algorithms we are going to consider later.
</p>

<div class="highlighted">
<div class="theorem-title">Substitution with &#920-equivalent functions</div>
In expressions using asymptotic notation we can substitute functions with other functions that are &#920-equivalent to the original functions. More formally:
<ol>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
  <li>
  If
  <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
</ol>

<p>
These observations allow us to freely substitute functions with their &#920-equivalent functions which may allow us to potentially simplify expressions that use asymptotic notation.
</p>
</div>
<div class="artefact-label" href="#1.11">1.11 - Substitution with &#920-equivalent functions</div>

<p>
<div class="section-label">Proof:</div>
</p>

<p>
  Let's prove all the points stated above starting with the first one.
</p>

<p>
  <ol>
    <li>
<p>
We know that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. According to the definition 1.9 of &#920-notation this means that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math>. Then by definition 1.7 of o-notation we can find constants <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
  <mi>C</mi>
  <mi>1</mi>
</msub>
<mo>,</mo>
<msub>
  <mi>C</mi>
  <mi>2</mi>
</msub>
</math> and natural numbers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
  <mi>N</mi>
  <mi>1</mi>
</msub>
<mo>,</mo>
<msub>
  <mi>N</mi>
  <mi>2</mi>
</msub>
</math> such that for all natural <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>&ge;</mo>
<msub>
  <mi>N</mi>
  <mi>1</mi>
</msub>
</math> we have <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>&ge;</mo>
<msub>
  <mi>C</mi>
  <mi>1</mi>
</msub>
<mo>*</mo>
<mi>g</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math> and for all natural <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>&ge;</mo>
<msub>
  <mi>N</mi>
  <mi>2</mi>
</msub>
</math> we have <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>&ge;</mo>
<msub>
  <mi>C</mi>
  <mi>2</mi>
</msub>
<mo>*</mo>
<mi>f</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math>. Then if we take <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>N</mi>
<mo>=</mo>
<mo>max</mo>
<mo>(</mo>
<msub>
  <mi>N</mi>
  <mi>1</mi>
</msub>
<mo>,</mo>
<msub>
  <mi>N</mi>
  <mi>2</mi>
</msub>
<mo>)</mo>
</math> we see for all natural <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>&ge;</mo>
<mi>N</mi>
</math> that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>&ge;</mo>
<msub>
  <mi>C</mi>
  <mi>2</mi>
</msub>
<mo>*</mo>
<mi>f</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>&ge;</mo>
<msub>
  <mi>C</mi>
  <mi>2</mi>
</msub>
<mo>*</mo>
<msub>
  <mi>C</mi>
  <mi>1</mi>
</msub>
<mo>*</mo>
<mi>g</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math>. If we take <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>C</mi>
<mo>=</mo>
<msub>
  <mi>C</mi>
  <mi>1</mi>
</msub>
<mo>*</mo>
<msub>
  <mi>C</mi>
  <mi>2</mi>
</msub>
</math> then we see that by definition 1.7 of o-notation we have <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> which is precisely what we wanted to prove.
</p>
<p>
In the process of proving the first point we also proved the following fact which will be useful for proving the second point: if <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>. We can call this fact transitivity of o.
</p>
    </li>
    <li>
      Proof is done in a similar fashion. Given that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> by definition 1.9 of &#920-notation we have <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, which according to the definition of 1.8 of O-notation is the same as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>. Now combining this with <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> we see according to the transitivity of o that was proved above that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> which is exactly what we wanted to prove.
    </li>
    <li>
      Given that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, which according to the definition 1.8 of O-notation is the same as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and having <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> according to already proven point 2 we see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> which again according to the definition 1.8 of O-notation is the same as <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> which is what we wanted to prove.
    </li>
    <li>
      Similar to the previously proven point we have <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> which allows us to apply the first point of the theorem and see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> which we wanted to prove.
    </li>
    <li>
      According to the definition 1.9 of &#920-notation <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, then combining this with <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>f</mi>
<mo>)</mo>
</math> and the proven points 1 and 3 of the present theorem we see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> which by definition means <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and the point is proven.
    </li>
    <li>
      In a fashion similar to the previous point, we apply the definition of &#920-notation twice and the proven points 2 and 4 of the present theorem to prove that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> &#x25a0;
    </li>
  </ol>
</p>

<div class="highlighted no-artefact-label">
  <div class="note-title">Using equality = in asymptotic notation</div>
<p>
Now it is time for a quick necessary note on the terminology and notation. Up until this moment we were writing <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> meaning that f belongs to a set of functions that are <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>. In no way did we imply with the = sign that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> is equal to that set of functions. In fact it would be much more sensible to write <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>&isin;</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, meaning <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>f</mi></math> belongs to the set of functions that are <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> instead of <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>.
</p>
<p>
For historical reasons we will continue to use the former notation and write informally that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, at the same time understanding that the equality = here is a special kind of equality, more like belonging to a set.
</p>
<p>
Now, if we informally write later something like <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
<mo>+</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> it does not mean that we take a set of functions that are <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and add it to itself. There is nothing strange in adding two sets, it may just mean, for example, taking the union of two sets: a new set that contains all the elements of the original sets. But in this case everything is much simpler: we are just looking at <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>+</mo>
<mi>h</mi>
</math> where <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>.
</p>
</div>

<p>
Now let's formulate a few additional properties of o, O, and &#920 that will be useful for us when we will be estimating the time complexity of different algorithms. Proving the following theorems is left to the reader as an exercise.
</p>

<div class="highlighted">
<div class="theorem-title">Arithmetic operations and asymptotic notation</div>
<ol>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
</math> is a constant, then <math>
<mi>f</mi>
<mo>+</mo>
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
<mo>*</mo>
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
</math> is a constant, then <math>
<mi>f</mi>
<mo>+</mo>
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
<mo>*</mo>
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
</math> is a constant, then <math>
<mi>f</mi>
<mo>+</mo>
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>, <math>
<mi>C</mi>
<mo>*</mo>
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>
  </li>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>u</mi>
<mo>)</mo>
</math>, <math>
<mi>f</mi>
<mo>,</mo>
<mi>g</mi>
<mo>,</mo>
<mi>h</mi>
<mo>,</mo>
<mi>u</mi>
<mo>&gt;</mo>
<mi>0</mi>
</math>, then <math>
<mi>f</mi>
<mo>*</mo>
<mi>h</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>*</mo>
<mi>u</mi>
<mo>)</mo>
</math>
  </li>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>u</mi>
<mo>)</mo>
</math>, <math>
<mi>f</mi>
<mo>,</mo>
<mi>g</mi>
<mo>,</mo>
<mi>h</mi>
<mo>,</mo>
<mi>u</mi>
<mo>&gt;</mo>
<mi>0</mi>
</math>, then <math>
<mi>f</mi>
<mo>*</mo>
<mi>h</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>*</mo>
<mi>u</mi>
<mo>)</mo>
</math>
  </li>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>u</mi>
<mo>)</mo>
</math>, <math>
<mi>f</mi>
<mo>,</mo>
<mi>g</mi>
<mo>,</mo>
<mi>h</mi>
<mo>,</mo>
<mi>u</mi>
<mo>&gt;</mo>
<mi>0</mi>
</math>, then <math>
<mi>f</mi>
<mo>*</mo>
<mi>h</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>*</mo>
<mi>u</mi>
<mo>)</mo>
</math>
  </li>
</ol>
</p>

<p>
The theorem essentially says that if add and multiply by a constant then the asymptotic properties of functions are preserved.
</p>
</div>
<div class="artefact-label" href="#1.12">1.12 - Arithmetic operations and asymptotic notation</div>

<div class="highlighted">
<div class="theorem-title">Transitivity of asymptotic notation</div>
<ol>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>g</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> then
<math>
<mi>f</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>g</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> then
<math>
<mi>f</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
  <li>
    If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>g</mi>
<mo>)</mo>
</math>,
<math>
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math> then
<math>
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
  </li>
</ol>
</p>

<p>
Essentially the asymptotic notation behaves a like the normal comparison operators and equality: <math>
<mi>o</mi>
</math> is like <math>
<mo>&ge;</mo>
</math>, <math>
<mi>O</mi>
</math> is like <math>
<mo>&le;</mo>
</math> and <math>
<mi>&#920</mi>
</math> is like <math>
<mo>=</mo>
</math>. And we know that from, for example, <math>
<mi>x</mi>
<mo>&ge;</mo>
<mi>y</mi>
</math>, <math>
<mi>y</mi>
<mo>&ge;</mo>
<mi>z</mi>
</math> follows that <math>
<mi>x</mi>
<mo>&ge;</mo>
<mi>z</mi>
</math>.
</p>
</div>
<div class="artefact-label" href="#1.12">1.13 - Transitivity of asymptotic notation</div>

<div class="highlighted">
<div class="theorem-title">Preserving &#920-behavior</div>
If <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>f</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>,
<math>
<mi>g</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>, <math>
<mi>g</mi>
<mo>&ge;</mo>
<mi>0</mi>
</math> then
<math>
<mi>f</mi>
<mo>+</mo>
<mi>g</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>h</mi>
<mo>)</mo>
</math>
</p>

<p>
This means that when dealing with asymptotic notation we can simplify expressions by disregarding the O part and leaving the &#920 part, informally we can say that "&#920 plus O is still &#920".
</p>
</div>
<div class="artefact-label" href="#1.14">1.14 - Preserving &#920-behavior</div>

<p>
Based on the theorems above we can now reason more easily about the asymptotic notation and simplify expressions in order to get rid of the unnecessary details.
</p>

<p>
That was quite a bit of formalization, and if you feel a bit confused, don't despair, all will become much clearer after a few simple examples. But even if you still do not grasp the mathematics behind the definition then hopefully you will have at least some intuitive feeling of what the asymptotic notation actually means.
</p>

<div class="highlighted no-artefact-label">
  <div class="example-title">Examples of asymptotic notation</div>
<ol>
<li>
<div>
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msup>
  <mi>n</mi>
  <mn>2</mn>
</msup>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mrow>
  <mi>n</mi>
</mrow>
<mo>)</mo>
</math>
and
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mrow>
  <msup>
    <mi>n</mi>
    <mn>2</mn>
  </msup>
</mrow>
<mo>)</mo>
</math>
</div>

This is obvious according to the given definition 1.7 of o-notation, we just need to find 
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>C</mi></math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>N</mi></math> from the definition. But this is relatively easy in this case, we just take <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>C</mi>
  <mo>=</mo>
  <mi>1</mi>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>N</mi>
  <mo>=</mo>
  <mi>2</mi>
</math> we see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msup>
  <mi>n</mi>
  <mn>2</mn>
</msup>
<mo>&ge;</mo>
<mi>n</mi>
</math> and then by definition <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msup>
  <mi>n</mi>
  <mn>2</mn>
</msup>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mrow>
  <mi>n</mi>
</mrow>
<mo>)</mo>
</math>. But even intuitively it is clear that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msup>
  <mi>n</mi>
  <mn>2</mn>
</msup>
</math> at some point becomes larger than <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>n</mi>
</math>. Then by definition 1.8 of O-notation we also immediately see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mrow>
  <msup>
    <mi>n</mi>
    <mn>2</mn>
  </msup>
</mrow>
<mo>)</mo>
</math>.
</li>
<li>
  <div>
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mrow>
  <mi>8</mi>
</mrow>
<mo>)</mo>
</math>
and
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>8</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mrow>
  <mi>n</mi>
</mrow>
<mo>)</mo>
</math>
</div>
<p>
We just again note that we take <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>C</mi>
  <mo>=</mo>
  <mi>1</mi>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>N</mi>
  <mo>=</mo>
  <mi>8</mi>
</math> or even <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>C</mi>
  <mo>=</mo>
  <mfrac>
    <mo>1</mo>
    <mo>2</mo>
  </mfrac>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>N</mi>
  <mo>=</mo>
  <mi>4</mi>
</math>, or <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>C</mi>
  <mo>=</mo>
  <mi>8</mi>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
  <mi>N</mi>
  <mo>=</mo>
  <mfrac>
    <mo>1</mo>
    <mo>8</mo>
  </mfrac>
</math>, and we also see that there is a considerable amount of freedom in choosing the constants.
</p>
<p>
According to the theorem 1.11 about substituting functions with their &#920-equivalent functions and noting that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>8</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mrow>
  <mi>1</mi>
</mrow>
<mo>)</mo>
</math> we also see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mrow>
  <mi>1</mi>
</mrow>
<mo>)</mo>
</math>
and
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>1</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mrow>
  <mi>n</mi>
</mrow>
<mo>)</mo>
</math>.
</p>
</li>
<li>
<div>
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>10</mi>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>+</mo>
<mi>243</mi>
<msup>
<mi>n</mi>
<mn>3</mn>
</msup>
<mo>+</mo>
<mi>41</mi>
<mi>n</mi>
<mo>+</mo>
<mi>5</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>)</mo>
</math>
</div>
<p>
Indeed, first according to the theorem 1.12 about arithmetic operations we note that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>10</mi>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>)</mo>
</math>, then we see directly from definition 1.8 of O that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>243</mi>
<msup>
<mi>n</mi>
<mn>3</mn>
</msup>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>)</mo>
</math>, <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>41</mi>
<mi>n</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>)</mo>
</math>, and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>5</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>)</mo>
</math>. According to the theorem 1.12 about arithmetic operations we also note that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>243</mi>
<msup>
<mi>n</mi>
<mn>3</mn>
</msup>
<mo>+</mo>
<mi>41</mi>
<mi>n</mi>
<mo>+</mo>
<mi>5</mi>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>)</mo>
</math>, which combined with the knowledge that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>10</mi>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>)</mo>
</math> according to the theorem 1.14 of preserving the &#920 behavior means <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>10</mi>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>+</mo>
<mi>243</mi>
<msup>
<mi>n</mi>
<mn>3</mn>
</msup>
<mo>+</mo>
<mi>41</mi>
<mi>n</mi>
<mo>+</mo>
<mi>5</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mn>4</mn>
</msup>
<mo>)</mo>
</math>.
</p>
</li>
<li>
<div>
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msup>
<mi>e</mi>
<mn>n</mn>
</msup>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mn>10</mn>
</msup>
<mo>)</mo>
</math>
</div>
<p>
The proof is a bit more involved and will be omitted here.
</p>
</li>
</ul>
</div>

<p>
Later we may also use special names for various functions depending on their asymptotic behavior. We call "linear" all the functions that belong to <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>&#920</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math>. "Linear" functions are a particular case of "polynomial" functions, which are precisely the class of functions that are <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>&#920</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mn>k</mn>
</msup>
<mo>)</mo>
</math> where <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>k</mi>
</math> is a natural number. Functions that are <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>&#920</mi>
<mo>(</mo>
<msup>
<mi>a</mi>
<mn>n</mn>
</msup>
<mo>)</mo>
</math> for some <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>a</mi>
<mo>&gt;</m0>
<mi>0</mi>
</math> are called "exponential".
</p>

<p>
The introduced asymptotic notation universal in the sense that we can use it for analyzing not only time complexity but the behavior of any functions of single argument when their argument indefinitely grows to plus infinity.
</p>

<p>
We should note at this point that although the asymptotic notation can be useful when analyzing and comparing time complexities of algorithms it certainly has its limits. For example, if the input size for a particular problem we are trying to solve stays relatively small, then we would like to compare not the asymptotic behavior but absolute values of the functions. In this case exponential time complexity <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msup>
<mi>2</mi>
<mn>n</mn>
</msup>
</math> is in fact preferrable to the linear time complexity <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>10000</mi>
<mi>n</mi>
</math> for <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>&le;</mo>
<mi>10</mi>
</math>.
</p>

<p>
Note, that once the input size starts growing beyond 10 the exponential functions starts to loose out to the linear one dramatically. And as we noted before, informally, probably for small input sizes all the algorithms execute for a relatively short time. This is in fact, why we analyze the asymptotic behavior.
</p>

<p>
But also note that if <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>&le;</mo>
<mi>5</mi>
</math> then the exponential function is more than 100 faster than the linear one which is quite a lot.
</p>

<p>
No confusion should happen here, it is just for small input sizes the asymptotic behavior matters much less than the constants that occur in the functions (like 10000 in this example) and absolute values. If we are doing some optimization for small or medium inputs then we should compare the function values, and not just the asymptotic behavior which may be quite irrelevant in this case as we have just shown. Each tool has natural boundaries and conditions inside which it should be best applied, the asymptotic notation is in no way different.
</p>

<h2>Storage complexity</h2>

<p>
Another important characteristic that can be used to describe and compare the efficiency of different algorithms is storage complexity. If time complexity shows how fast an algorithm executes the storage complexity shows how much memory space it takes.
</p>

<p>
When comparing algorithms we should not just compare execution times, but rather look at the bigger picture and various characteristics such as storage complexity. Intuitively, if we have a somewhat faster algorithm that consumes a lot of memory, we may prefer its slower alternative which is more memory-efficient.
</p>

<p>
Let us now define the storage complexity. Just like for time complexity we need to take into account that algorithms can have various inputs of varying size being provided.
</p>

<div class="highlighted">
<div class="definition-term">Storage complexity of algorithm</div>
<p>
Given an algorithm, a set of its possible inputs, and the distribution (relative frequencies) of the inputs, we define the storage complexity of this algorithm as the average number of different variables it takes the algorithm to complete its work.
</p>
<p>
Analogous to the time complexity case the function that determines the input size for a given algorithm input is normally selected in such a manner that the storage complexity can be expressed as a function of the input size. In case an algorithm uses an array or complex data structure we count as a separate variable each primitive element of the array or field of the object.
</p>
</div>
<div class="artefact-label" href="#1.15">1.15 - Storage complexity of algorithm</div>

<p>
Just like time complexity, normally storage complexity increases as the input size grows. And then we can just re-use the same asymptotic notation we introduced above and talk about "linear", "polynomial", "exponential", etc. storage complexity.
</p>

<p>
We can of course consider other measures of how efficient algorithm is, not just the time and storage complexity but, for example, the size of the algorithm specification (number of lines of JavaScript code in case of JavaScript programs). Some algorithms can be better than others not only in terms of execution time but also storage space and brevity, but quite often we have to compare two algorithms one of which is faster but consumes more memory. In this case we face a trade-off of storage vs. speed and have to decide what is more important and consider the storage and time complexity together. We will see an example of such algorithms later in this chapter when we solve the problem of finding all prime numbers less than a given number.
</p>

<h2>Eratosthenes sieve</h2>

<p>
A prime number is a number that cannot be divided without a remainder by any number less than it.
</p>

<div class="highlighted">
<div class="definition-term">Prime number</div>
<p>
A positive integer number <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>n</mi></math> greater than <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>1</mi></math> is called "prime" if there does not exist a number <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>1</mi>
<mo>&lt;</mo>
<mi>k</mi>
<mo>&lt;</mo>
<mi>n</mi>
</math> such that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mfrac>
<mi>n</mi>
<mi>k</mi>
</mfrac>
</math> is an integer number.
</p>
<p>
That is a prime number is a special kind of number that does not have numbers that can divide it except for <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>1</mi></math> and the number itself.
</p>
</div>
<div class="artefact-label" href="#1.16">1.16 - Prime number</div>

<p>
Now we will consider a couple of algorithms for finding all prime numbers that are less than a given number and then use the developed mathematical means to estimate and compare their time and storage complexity.
</p>

<p>
The first algorithm is based on the just given definition. First, let's define a function that checks if the number is prime.
</p>

<pre class="line-numbers language-javascript">
<code>function isPrime(number) {
  for (var i = 2; i < number; i++) {
    if (number % i == 0) {
      return false;
    }
  }
  return true;
}</code>
</pre>

<p>
In the line 2 we iterate over all the numbers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>1</mi>
<mo>&lt;</mo>
<mi>i</mi>
<mo>&lt;</mo>
<mi>n</mi>
</math> and for each one of them check if <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>i</mi></math> divides the given number in the line 3. If it does, then by definition 1.16 the given number is not prime and we return <i>false</i> in the line 4. If on the other hand we iterated through all the numbers other than <i>1</i> and <i>number</i> and none of them divides <i>number</i> then by definition 1.16 <i>number</i> is prime and we return <i>true</i>.
</p>

<p>
Now we still need a function that would iterate through all the numbers smaller than the given one and determine if they are prime. For testing whether a number is prime we just defined the function <i>isPrime</i> and can already use it.
</p>

<pre class="line-numbers language-javascript">
<code>function primesUpTo(number) {
    var primes = [];

    for (var current = 2; current <= number; current++) {
      if (isPrime(current)) {
        primes.push(current);
      }
    }
    return primes;
  }</code>
</pre>

<p>
In line 2 we initialize the array of all the found primes to an empty array and then in lines 4-8 we iterate over all the potentially prime numbers and check for every number if it is indeed prime in the line 5. Then if it is prime we push it into the array of found prime numbers in line 6. Once we looked through all the potentially prime numbers we return the accumulated result in line 9.
</p>

<p>
What about the time and storage complexity of the algorithm? First we will choose the input size as the number we provide as an input, let's say that this number is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>n</mi></math>.
</p>

<p>
The time complexity is easy to estimate by looking at the implementation of <i>isPrime</i> and <i>primesUpTo</i>.
</p>
<p>
It is relatively easy to note from the code that <i>isPrime</i> performs not fewer than <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>-</mo>
<mi>1</mi>
</math> steps and no more than <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>3</mi>
<mi>n</mi>
<mo>-</mo>
<mi>1</mi>
</math>, which means that time complexity <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
<mi>t</mi>
<mi>isPrime</mi>
</msub>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>n</mi>
<mo>-</mo>
<mi>1</mi>
<mo>)</mo>
</math> and <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
<mi>t</mi>
<mi>isPrime</mi>
</msub>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>=</mo>
<mi>o</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math> according to the theorem 1.11 about substitution with equivalent functions since <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>-</mo>
<mi>1</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math>. In a similar way we note that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
<mi>t</mi>
<mi>isPrime</mi>
</msub>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>3</mi>
<mi>n</mi>
<mo>)</mo>
</math> which after applying theorem 1.12 about artihmetic operations with asymptotic notation means that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
<mi>t</mi>
<mi>isPrime</mi>
</msub>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>=</mo>
<mi>O</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math>, and then <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
<mi>t</mi>
<mi>isPrime</mi>
</msub>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math> for the time complexity of <i>isPrime</i>.
</p>

<p>
Now let's consider <i>primesUpTo</i>. The code of the function closely resembles that of <i>isPrime</i>, and the number of steps is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
<mi>t</mi>
<mi>primesUpTo</mi>
</msub>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>n</mi>
<mo>*</mo>
<msub>
<mi>t</mi>
<mi>isPrime</mi>
</msub>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>)</mo>
</math> as it can be seen similarly to what we have done when measured the time complexity of <i>isPrime</i>. We note that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
</math>, then according to the theorem 1.12 about arithmetic operations with asymptotic notation point 6 we see that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>n</mi>
<mo>*</mo>
<msub>
<mi>t</mi>
<mi>isPrime</mi>
</msub>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>n</mi>
<mo>*</mo>
<mi>n</mi>
<mo>)</mo>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mi>2</mi>
</msup>
<mo>)</mo>
</math>
and
<math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
<mi>t</mi>
<mi>primesUpTo</mi>
</msub>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<mi>&#920</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mi>2</mi>
</msup>
<mo>)</mo>
<mo>)</mo>
</math> which according to the theorem 1.13 about the transitivity of asymptotic notation means that <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<msub>
<mi>t</mi>
<mi>primesUpTo</mi>
</msub>
<mo>(</mo>
<mi>n</mi>
<mo>)</mo>
<mo>=</mo>
<mi>&#920</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mi>2</mi>
</msup>
<mo>)</mo>
</math>.
</p>

<p>
Later in the book we, probably, will not be doing such a detailed analysis and will just provide a reasonable and much shorter explanation of how we estimate particular time complexity appealing more to intuition than to the formal reasoning. But even then we can provide a full formal proof based on the theorems about the asymptotic notation and counting number of steps precisely. At least, we should have definitely provided one full detailed explanation how we get the time complexity in this case. In the future this will be mostly left as an exercise for a curious reader.
</p>

<p>
We will take a more informal approach already starting with estimating the storage complexity of the algorithm above.
</p>

<p>
The function <i>isPrime</i> uses two variables and has the storage complexity <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>O</mi><mo>(</mo><mi>1</mi><mo>)</mo></math>. This function is called <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>n</mi></math> times where <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>n</mi></math> is the input size (the upper limit up until which we are searching for prime numbers). Then just like for the time complexity we see that <i>isPrime</i> contributes <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>O</mi><mo>(</mo><mi>n</mi><mo>)</mo></math> to the overall storage complexity of the algorithm. But if we additionally assume that the variables used during different invokations of <i>isPrime</i> are reused and are actually the same variables, then it is obvious that the storage complexity is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>&#920</mi><mo>(</mo><mi>1</mi><mo>)</mo></math> since only <i>2</i> variables are used.
</p>

<p>
Now let's look at the function <i>primesUpTo</i>. It creates and uses an array which maximum size is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>n</mi></math> where <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>n</mi></math> is the size of input. Then <i>primesUpTo</i> has the storage complexity of <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>&#920</mi><mo>(</mo><mi>n</mi><mo>)</mo></math> taking into account that as we discovered earlier <i>isPrime</i> has the time complexity of <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>&#920</mi><mo>(</mo><mi>1</mi><mo>)</mo></math>. Note that we really cannot easily say much more about the storage complexity of <i>primesUpTo</i> and hence of the algorithm in terms of &#920. The storage complexity is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>&#920</mi><mo>(</mo><mi>p</mi><mo>(</mo><mi>n</mi><mo>)</mo><mo>)</mo></math> where <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>p</mi></math> is the function that gives the number of prime numbers which are less or equal than <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>n</mi></math>.
</p>

<p>
So, as we just have shown the time complexity of the algorithm based on the given definition of prime numbers is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression">
<mi>&#920</mi>
<mo>(</mo>
<msup>
<mi>n</mi>
<mi>2</mi>
</msup>
<mo>)</mo>
</math> and the storage complexity is <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>O</mi><mo>(</mo><mi>n</mi><mo>)</mo></math>.
</p>

<p>
These are quite satisfactory results as the studied algorithm is not particularly slow or memory-consuming. But let's see if we can improve it still. For example, let's think whether it is possible to find prime numbers in a linear time. The algorithm we will discuss does just that and is called "Eratosthenes sieve" because of the way we sift through all the numbers trying to find out which ones are prime.
</p>

<p>
The idea is quite simple. We iterate over all the numbers that are less than a given one and for each such number <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>k</mi></math> we subsequently exclude from further consideration numbers <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>2</mi><mi>k</mi> </math>, <math xmlns='http://www.w3.org/1998/Math/MathML' class="math-expression"><mi>3</mi><mi>k</mi></math>, ... until we reach such a k-fold number which is greater than the original given number. If some k-fold number was already excluded at an earlier stage, we just skip it. Then we exclude the current number and move on to the next number that was not yet excluded. If we take on each step the smallest not yet excluded number, than this number, simply because it would have been excluded otherwise on the earlier steps, has the property that it cannot be divided by any number which is less than it and is not <i>1</i>. Or by definition the smallest unexcluded number is prime. If one each step we remember the current number as prime then after we have considered all the numbers less than a given one we will have the list of all prime numbers less than a given one. Let's give a quick illustration of how this algorithm might work if the given number is <i>15</i>.
</p>

<div class="medium illustration">
  <img src="chapters/chapter1/svg/1.1.eratosthenes.sieve.svg" title="Sieve of Eratosthenes up to 15"/>
  <div class="artefact-label">1.17 - Sieve of Eratosthenes up to 15</div>
</div>

<p>
First we have no numbers excluded and the smallest non-excluded number is <i>2</i>. We remember that <i>2</i> is prime and cross out <i>4</i>, <i>6</i>, <i>8</i>, <i>10</i>, <i>12</i>, <i>14</i>. After noting that <i>2</i> is prime we exclude it too.
</p>

<p>
Now the smallest non-excluded number is <i>3</i>. We remember that it is prime and exclude number <i>9</i>. The numbers <i>6</i> and <i>12</i> were already excluded on the previous step so we just skip them. Then we exclude <i>3</i>.
</p>

<p>
The next smallest non-excluded number is <i>5</i>. The only number that is divided by it and is less or equal than <i>15</i> is actually number <i>15</i> itself. We exclude it on this step.
</p>

<p>
The next non-excluded number is <i>7</i> and all the 7-fold numbers less or equal to <i>15</i> were already excluded.
</p>

<p>
The next are <i>11</i> and <i>13</i> for which we do not have to exclude any numbers. The algorithm finishes its work and we found all the prime numbers less or equal than <i>15</i>. These numbers are <i>2</i>, <i>3</i>, <i>5</i>, <i>7</i>, <i>11</i>, <i>13</i>.
</p>

<p>
If this still sounds like something complicated, it is just because it is written in prose and maybe not formal enough. Let's provide the implementation in JavaScript and comment what we do on each step of the algorithm.
</p>

TODO: Implementation in JavaScript
TODO: Discuss that the algorithm is faster but more complicated, this is a trade-off

<h2>Euclidus algorithm</h2>

TODO: Discuss that the algorithm is faster and simpler at the same time

<p>Here goes the contents and some JavaScript code</p>

<pre class="line-numbers language-javascript">
<code>function max(elements) {
  var max;

  for (var i = 0; i < elements.length; i++) {
    if (max == undefined || elements[i] > max) {
      max = elements[i];
    }
  }
  return max;
}</code>
</pre>

<p>
And here goes an illustration:
</p>

<!-- TODO: Use Handlebars template to render such thing as an illustration? -->

<p>
And after that we can use an inline formula

<math xmlns='http://www.w3.org/1998/Math/MathML' class="inline-math">
  <msup>
    <mi>e</mi>
    <mrow>
      <mn>2</mn>
      <mi>x</mi>
      <mo>+</mo>
      <mn>1</mn>
    </mrow>
  </msup>
</math>

</p>